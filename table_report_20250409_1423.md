# Query Table: `4706729a33_table1.csv`

## Query Table Content

|  Name                                                                                                                                                                    |  Quant method    |  Size    |
|:-------------------------------------------------------------------------------------------------------------------------------------------------------------------------|:-----------------|:---------|
| [Experimental100percent_RAG.Q2_K.gguf](https://huggingface.co/RichardErkhov/crodri_-_Experimental100percent_RAG-gguf/blob/main/Experimental100percent_RAG.Q2_K.gguf)     | Q2_K             | 3.08GB   |
| [Experimental100percent_RAG.Q3_K_S.gguf](https://huggingface.co/RichardErkhov/crodri_-_Experimental100percent_RAG-gguf/blob/main/Experimental100percent_RAG.Q3_K_S.gguf) | Q3_K_S           | 3.5GB    |
| [Experimental100percent_RAG.Q3_K.gguf](https://huggingface.co/RichardErkhov/crodri_-_Experimental100percent_RAG-gguf/blob/main/Experimental100percent_RAG.Q3_K.gguf)     | Q3_K             | 3.77GB   |
| [Experimental100percent_RAG.Q3_K_M.gguf](https://huggingface.co/RichardErkhov/crodri_-_Experimental100percent_RAG-gguf/blob/main/Experimental100percent_RAG.Q3_K_M.gguf) | Q3_K_M           | 3.77GB   |
| [Experimental100percent_RAG.Q3_K_L.gguf](https://huggingface.co/RichardErkhov/crodri_-_Experimental100percent_RAG-gguf/blob/main/Experimental100percent_RAG.Q3_K_L.gguf) | Q3_K_L           | 4.0GB    |
...

**Query Table Model â†’ Titles**
- **RichardErkhov/crodri_-_Experimental100percent_RAG-gguf**:
    - Raw Titles: ['richarderkhov (richard erkhov) Â· github', 'you can request more quants here']
    - Valid Titles: []

## Retrieved Tables

### Top 1: `c099770781_table1.csv`

|  Name                                                                                                                    |  Quant method    |  Size    |
|:-------------------------------------------------------------------------------------------------------------------------|:-----------------|:---------|
| [test-last.Q2_K.gguf](https://huggingface.co/RichardErkhov/gemmathon_-_test-last-gguf/blob/main/test-last.Q2_K.gguf)     | Q2_K             | 1.08GB   |
| [test-last.Q3_K_S.gguf](https://huggingface.co/RichardErkhov/gemmathon_-_test-last-gguf/blob/main/test-last.Q3_K_S.gguf) | Q3_K_S           | 1.2GB    |
| [test-last.Q3_K.gguf](https://huggingface.co/RichardErkhov/gemmathon_-_test-last-gguf/blob/main/test-last.Q3_K.gguf)     | Q3_K             | 1.29GB   |
| [test-last.Q3_K_M.gguf](https://huggingface.co/RichardErkhov/gemmathon_-_test-last-gguf/blob/main/test-last.Q3_K_M.gguf) | Q3_K_M           | 1.29GB   |
| [test-last.Q3_K_L.gguf](https://huggingface.co/RichardErkhov/gemmathon_-_test-last-gguf/blob/main/test-last.Q3_K_L.gguf) | Q3_K_L           | 1.36GB   |
...

**ModelÂ â†’Â Titles**
- **RichardErkhov/gemmathon_-_test-last-gguf**:
    - Raw Titles: ['richarderkhov (richard erkhov) Â· github', 'you can request more quants here', 'quantifying the carbon emissions of machine learning']
    - Valid Titles: ['quantifying the carbon emissions of machine learning']


### Top 2: `ad1c70f54c_table1.csv`

|  Name                                                                                                                  |  Quant method    |  Size    |
|:-----------------------------------------------------------------------------------------------------------------------|:-----------------|:---------|
| [PiVoT-MoE.Q2_K.gguf](https://huggingface.co/RichardErkhov/maywell_-_PiVoT-MoE-gguf/blob/main/PiVoT-MoE.Q2_K.gguf)     | Q2_K             | 12.28GB  |
| [PiVoT-MoE.Q3_K_S.gguf](https://huggingface.co/RichardErkhov/maywell_-_PiVoT-MoE-gguf/blob/main/PiVoT-MoE.Q3_K_S.gguf) | Q3_K_S           | 14.5GB   |
| [PiVoT-MoE.Q3_K.gguf](https://huggingface.co/RichardErkhov/maywell_-_PiVoT-MoE-gguf/blob/main/PiVoT-MoE.Q3_K.gguf)     | Q3_K             | 16.1GB   |
| [PiVoT-MoE.Q3_K_M.gguf](https://huggingface.co/RichardErkhov/maywell_-_PiVoT-MoE-gguf/blob/main/PiVoT-MoE.Q3_K_M.gguf) | Q3_K_M           | 16.1GB   |
| [PiVoT-MoE.Q3_K_L.gguf](https://huggingface.co/RichardErkhov/maywell_-_PiVoT-MoE-gguf/blob/main/PiVoT-MoE.Q3_K_L.gguf) | Q3_K_L           | 17.45GB  |
...

**ModelÂ â†’Â Titles**
- **RichardErkhov/maywell_-_PiVoT-MoE-gguf**:
    - Raw Titles: ['richarderkhov (richard erkhov) Â· github', 'you can request more quants here']
    - Valid Titles: []


### Top 3: `a22e47b33b_table1.csv`

|  Name                                                                                                                     |  Quant method    |  Size    |
|:--------------------------------------------------------------------------------------------------------------------------|:-----------------|:---------|
| [gpt2-large.Q2_K.gguf](https://huggingface.co/RichardErkhov/quintic_-_gpt2-large-gguf/blob/main/gpt2-large.Q2_K.gguf)     | Q2_K             | 0.32GB   |
| [gpt2-large.Q3_K_S.gguf](https://huggingface.co/RichardErkhov/quintic_-_gpt2-large-gguf/blob/main/gpt2-large.Q3_K_S.gguf) | Q3_K_S           | 0.37GB   |
| [gpt2-large.Q3_K.gguf](https://huggingface.co/RichardErkhov/quintic_-_gpt2-large-gguf/blob/main/gpt2-large.Q3_K.gguf)     | Q3_K             | 0.43GB   |
| [gpt2-large.Q3_K_M.gguf](https://huggingface.co/RichardErkhov/quintic_-_gpt2-large-gguf/blob/main/gpt2-large.Q3_K_M.gguf) | Q3_K_M           | 0.43GB   |
| [gpt2-large.Q3_K_L.gguf](https://huggingface.co/RichardErkhov/quintic_-_gpt2-large-gguf/blob/main/gpt2-large.Q3_K_L.gguf) | Q3_K_L           | 0.46GB   |
...

**ModelÂ â†’Â Titles**
- **RichardErkhov/quintic_-_gpt2-large-gguf**:
    - Raw Titles: ['richarderkhov (richard erkhov) Â· github', 'you can request more quants here']
    - Valid Titles: []


### Top 4: `5ef0488fe9_table1.csv`

|  Name                                                                                                                                                |  Quant method    |  Size    |
|:-----------------------------------------------------------------------------------------------------------------------------------------------------|:-----------------|:---------|
| [generative-qa-model.Q2_K.gguf](https://huggingface.co/RichardErkhov/blapuma_-_generative-qa-model-gguf/blob/main/generative-qa-model.Q2_K.gguf)     | Q2_K             | 1.32GB   |
| [generative-qa-model.IQ3_XS.gguf](https://huggingface.co/RichardErkhov/blapuma_-_generative-qa-model-gguf/blob/main/generative-qa-model.IQ3_XS.gguf) | IQ3_XS           | 1.51GB   |
| [generative-qa-model.IQ3_S.gguf](https://huggingface.co/RichardErkhov/blapuma_-_generative-qa-model-gguf/blob/main/generative-qa-model.IQ3_S.gguf)   | IQ3_S            | 1.57GB   |
| [generative-qa-model.Q3_K_S.gguf](https://huggingface.co/RichardErkhov/blapuma_-_generative-qa-model-gguf/blob/main/generative-qa-model.Q3_K_S.gguf) | Q3_K_S           | 1.57GB   |
| [generative-qa-model.IQ3_M.gguf](https://huggingface.co/RichardErkhov/blapuma_-_generative-qa-model-gguf/blob/main/generative-qa-model.IQ3_M.gguf)   | IQ3_M            | 1.73GB   |
...

**ModelÂ â†’Â Titles**
- **RichardErkhov/blapuma_-_generative-qa-model-gguf**:
    - Raw Titles: ['richarderkhov (richard erkhov) Â· github', 'you can request more quants here', 'quantifying the carbon emissions of machine learning']
    - Valid Titles: ['quantifying the carbon emissions of machine learning']


### Top 5: `6f90f1f7d5_table1.csv`

|  Name                                                                                                             |  Quant method    |  Size    |
|:------------------------------------------------------------------------------------------------------------------|:-----------------|:---------|
| [gemma-7.Q2_K.gguf](https://huggingface.co/RichardErkhov/tomaszki_-_gemma-7-gguf/blob/main/gemma-7.Q2_K.gguf)     | Q2_K             | 1.08GB   |
| [gemma-7.Q3_K_S.gguf](https://huggingface.co/RichardErkhov/tomaszki_-_gemma-7-gguf/blob/main/gemma-7.Q3_K_S.gguf) | Q3_K_S           | 1.2GB    |
| [gemma-7.Q3_K.gguf](https://huggingface.co/RichardErkhov/tomaszki_-_gemma-7-gguf/blob/main/gemma-7.Q3_K.gguf)     | Q3_K             | 1.29GB   |
| [gemma-7.Q3_K_M.gguf](https://huggingface.co/RichardErkhov/tomaszki_-_gemma-7-gguf/blob/main/gemma-7.Q3_K_M.gguf) | Q3_K_M           | 1.29GB   |
| [gemma-7.Q3_K_L.gguf](https://huggingface.co/RichardErkhov/tomaszki_-_gemma-7-gguf/blob/main/gemma-7.Q3_K_L.gguf) | Q3_K_L           | 1.36GB   |
...

**ModelÂ â†’Â Titles**
- **RichardErkhov/tomaszki_-_gemma-7-gguf**:
    - Raw Titles: ['richarderkhov (richard erkhov) Â· github', 'you can request more quants here', 'quantifying the carbon emissions of machine learning']
    - Valid Titles: ['quantifying the carbon emissions of machine learning']


### Top 6: `0c3ae48d95_table1.csv`

|  Name                                                                                                                                   |  Quant method    |  Size    |
|:----------------------------------------------------------------------------------------------------------------------------------------|:-----------------|:---------|
| [MG-FinalMix-72B.Q2_K.gguf](https://huggingface.co/RichardErkhov/Undi95_-_MG-FinalMix-72B-gguf/blob/main/MG-FinalMix-72B.Q2_K.gguf)     | Q2_K             | 27.76GB  |
| [MG-FinalMix-72B.Q3_K_S.gguf](https://huggingface.co/RichardErkhov/Undi95_-_MG-FinalMix-72B-gguf/blob/main/MG-FinalMix-72B.Q3_K_S.gguf) | Q3_K_S           | 32.12GB  |
| [MG-FinalMix-72B.Q3_K.gguf](https://huggingface.co/RichardErkhov/Undi95_-_MG-FinalMix-72B-gguf/blob/main/MG-FinalMix-72B.Q3_K.gguf)     | Q3_K             | 35.11GB  |
| [MG-FinalMix-72B.Q3_K_M.gguf](https://huggingface.co/RichardErkhov/Undi95_-_MG-FinalMix-72B-gguf/blob/main/MG-FinalMix-72B.Q3_K_M.gguf) | Q3_K_M           | 35.11GB  |
| [MG-FinalMix-72B.Q3_K_L.gguf](https://huggingface.co/RichardErkhov/Undi95_-_MG-FinalMix-72B-gguf/blob/main/MG-FinalMix-72B.Q3_K_L.gguf) | Q3_K_L           | 36.79GB  |
...

**ModelÂ â†’Â Titles**
- **RichardErkhov/Undi95_-_MG-FinalMix-72B-gguf**:
    - Raw Titles: ['richarderkhov (richard erkhov) Â· github', 'you can request more quants here']
    - Valid Titles: []


### Top 7: `1322ab795f_table1.csv`

|  Name                                                                                                                           |  Quant method    |  Size    |
|:--------------------------------------------------------------------------------------------------------------------------------|:-----------------|:---------|
| [ConvAI-9b.Q2_K.gguf](https://huggingface.co/RichardErkhov/CreitinGameplays_-_ConvAI-9b-gguf/blob/main/ConvAI-9b.Q2_K.gguf)     | Q2_K             | 3.13GB   |
| [ConvAI-9b.IQ3_XS.gguf](https://huggingface.co/RichardErkhov/CreitinGameplays_-_ConvAI-9b-gguf/blob/main/ConvAI-9b.IQ3_XS.gguf) | IQ3_XS           | 3.48GB   |
| [ConvAI-9b.IQ3_S.gguf](https://huggingface.co/RichardErkhov/CreitinGameplays_-_ConvAI-9b-gguf/blob/main/ConvAI-9b.IQ3_S.gguf)   | IQ3_S            | 3.67GB   |
| [ConvAI-9b.Q3_K_S.gguf](https://huggingface.co/RichardErkhov/CreitinGameplays_-_ConvAI-9b-gguf/blob/main/ConvAI-9b.Q3_K_S.gguf) | Q3_K_S           | 3.65GB   |
| [ConvAI-9b.IQ3_M.gguf](https://huggingface.co/RichardErkhov/CreitinGameplays_-_ConvAI-9b-gguf/blob/main/ConvAI-9b.IQ3_M.gguf)   | IQ3_M            | 3.79GB   |
...

**ModelÂ â†’Â Titles**
- **RichardErkhov/CreitinGameplays_-_ConvAI-9b-gguf**:
    - Raw Titles: ['richarderkhov (richard erkhov) Â· github', 'you can request more quants here']
    - Valid Titles: []


### Top 8: `e336968a76_table1.csv`

|  Name                                                                                                                                        |  Quant method    |  Size    |
|:---------------------------------------------------------------------------------------------------------------------------------------------|:-----------------|:---------|
| [Gemma_QA_ITA_v3.Q2_K.gguf](https://huggingface.co/RichardErkhov/DeepMount00_-_Gemma_QA_ITA_v3-gguf/blob/main/Gemma_QA_ITA_v3.Q2_K.gguf)     | Q2_K             | 1.08GB   |
| [Gemma_QA_ITA_v3.Q3_K_S.gguf](https://huggingface.co/RichardErkhov/DeepMount00_-_Gemma_QA_ITA_v3-gguf/blob/main/Gemma_QA_ITA_v3.Q3_K_S.gguf) | Q3_K_S           | 1.2GB    |
| [Gemma_QA_ITA_v3.Q3_K.gguf](https://huggingface.co/RichardErkhov/DeepMount00_-_Gemma_QA_ITA_v3-gguf/blob/main/Gemma_QA_ITA_v3.Q3_K.gguf)     | Q3_K             | 1.29GB   |
| [Gemma_QA_ITA_v3.Q3_K_M.gguf](https://huggingface.co/RichardErkhov/DeepMount00_-_Gemma_QA_ITA_v3-gguf/blob/main/Gemma_QA_ITA_v3.Q3_K_M.gguf) | Q3_K_M           | 1.29GB   |
| [Gemma_QA_ITA_v3.Q3_K_L.gguf](https://huggingface.co/RichardErkhov/DeepMount00_-_Gemma_QA_ITA_v3-gguf/blob/main/Gemma_QA_ITA_v3.Q3_K_L.gguf) | Q3_K_L           | 1.36GB   |
...

**ModelÂ â†’Â Titles**
- **RichardErkhov/DeepMount00_-_Gemma_QA_ITA_v3-gguf**:
    - Raw Titles: ['richarderkhov (richard erkhov) Â· github', 'you can request more quants here']
    - Valid Titles: []



---

# Query Table: `1903.06586_table13.csv`

## Query Table Content

| K3+ ReLU ?   | K5+ ReLU ?   |   Top-1 error (%) |
|:-------------|:-------------|------------------:|
| âœ“            | âœ—            |             28.65 |
| âœ—            | âœ“            |             28.4  |
| âœ—            | âœ—            |             28.36 |
| âœ“            | âœ“            |             28.49 |
...

## Retrieved Tables

### Top 1: `249395201_table5.csv`

|  Dataset     |    Value        |
|:-------------|----------------:|
| CIFAR-10     |           28.65 |
|              |           24.67 |
|              |           20.76 |
|              |           17.23 |
...

**ModelÂ â†’Â Titles**
- **zhendongw/diffusion-gan**:
    - Raw Titles: ["[neurips'21] projected gans converge faster", 'stargan v2 - official pytorch implementation (cvpr 2020)', 'flickr-faces-hq dataset (ffhq)', 'diffusion-gan: training gans with diffusion', '[neurips 2021] data-efficient instance generation from instance discrimination', 'stylegan2-ada - official pytorch implementation', 'lsun dataset documentation and demo code']
    - Valid Titles: ['diffusion-gan: training gans with diffusion']
- **zhendongw/prompt-diffusion**:
    - Raw Titles: ['github - timothybrooks/instruct-pix2pix', 'let us control diffusion models!', 'official pytorch implementation of the paper "in-context learning unlocked for diffusion models"', 'diffusion-gan: training gans with diffusion', 'in-context learning unlocked for diffusion models']
    - Valid Titles: ['diffusion-gan: training gans with diffusion']


### Top 2: `2409.12957_table14.csv`

| Methods   |   CLIP Scoreâ†‘â†‘\uparrow |
|:----------|-----------------------:|
| ShapE     |                  21.98 |
| 3DTopia   |                  22.54 |
| Ours      |                  24.33 |
...


### Top 3: `2312.16108_table6.csv`

|   Exp. | heads2r.   | ident. init.   |   mAP |   TOPlsls |
|-------:|:-----------|:---------------|------:|----------:|
|      1 | nan        | nan            |  28.8 |       5.6 |
|      2 | âœ“          | nan            |  29.1 |       6.2 |
|      3 | nan        | âœ“              |  30.6 |       7.9 |
|      4 | âœ“          | âœ“              |  32.6 |       8.1 |
...


### Top 4: `2312.04005_table0.csv`

| Distill type   |   HPSv2 |
|:---------------|--------:|
| SD-loss        |   25.53 |
| SA             |   26.74 |
| CA             |   26.11 |
| Res            |   26.27 |
| FFN            |   26.48 |
...


### Top 5: `2302.12242_table15.csv`

| Per Head?   | Per Layer?   |   mIoU |
|:------------|:-------------|-------:|
| no.         | no.          |   26.2 |
| yes.        | no.          |   27.8 |
| no.         | yes.         |   26.3 |
| yes.        | yes.         |   27.4 |
...


### Top 6: `2301.05586_table5.csv`

| BiC+SimCSPSPPF   | AAT   | DLD   | APval   |
|:-----------------|:------|:------|:--------|
| âœ—                | âœ—     | âœ—     | 43.5%   |
| âœ“                | âœ—     | âœ—     | 44.1%   |
| âœ“                | âœ“     | âœ—     | 44.4%   |
| âœ“                | âœ“     | âœ“     | 45.1%   |
...


### Top 7: `2301.05586_table10.csv`

| DLD   | Double epochs   | APval   |
|:------|:----------------|:--------|
| âœ—     | âœ—               | 44.4%   |
| âœ—     | âœ“               | 44.6%   |
| âœ“     | âœ—               | 45.1%   |
...


### Top 8: `2103.12693_table4.csv`

| important   | answered   |   Relevance Corr. |
|:------------|:-----------|------------------:|
| âœ“           | âœ“          |              37.6 |
| âœ“           | âœ—          |             -33.5 |
| âœ—           | âœ“          |              -5.7 |
...


### Top 9: `2103.05069v1_table2.csv`

| Model   | Data            |   ROUGE-1 |   ROUGE-L |
|:--------|:----------------|----------:|----------:|
| T5      | Abstract        |      28.5 |      16.6 |
| nan     | Abstract+Domain |      31.5 |      21.6 |
...

**ModelÂ â†’Â Titles**
- **anonymousparrot01/SubmissionModel**:
    - Raw Titles: ['title']
    - Valid Titles: ['title']



---

# Query Table: `268891288_table4.csv`

## Query Table Content

|    Layer                 |  0.0     |  0.2     |  0.4     |
|-------------------------:|:---------|:---------|:---------|
|                        0 | -        | -        | -        |
|                        1 | 0.2      | 0.0      | 0.4      |
|                        2 | -        | -        | -        |
|                        3 | 0.2      | 0.0      | 0.4      |
|                        4 | 0.0      | -        | -        |
...

**Query Table Model â†’ Titles**
- **sail/data-mixture-doremi-1b**:
    - Raw Titles: ['regmix: data mixture as regression for language model pre-training', 'a framework for few-shot evaluation of language models.', 'regmix/mixture_config/config_1b/doremi.yaml at main Â· sail-sg/regmix Â· github']
    - Valid Titles: ['regmix: data mixture as regression for language model pre-training']
- **sail/data-mixture-human-1b**:
    - Raw Titles: ['regmix: data mixture as regression for language model pre-training', 'a framework for few-shot evaluation of language models.', 'regmix/mixture_config/config_1b/human.yaml at main Â· sail-sg/regmix Â· github']
    - Valid Titles: ['regmix: data mixture as regression for language model pre-training']
- **sail/data-mixture-pile-cc-1b**:
    - Raw Titles: ['regmix: data mixture as regression for language model pre-training', 'a framework for few-shot evaluation of language models.', 'regmix/mixture_config/config_1b/human.yaml at main Â· sail-sg/regmix Â· github']
    - Valid Titles: ['regmix: data mixture as regression for language model pre-training']
- **sail/data-mixture-random-1b**:
    - Raw Titles: ['regmix: data mixture as regression for language model pre-training', 'a framework for few-shot evaluation of language models.']
    - Valid Titles: ['regmix: data mixture as regression for language model pre-training']
- **sail/data-mixture-regmix-1b**:
    - Raw Titles: ['regmix/mixture_config/config_1b/regmix.yaml at main Â· sail-sg/regmix Â· github', 'regmix: data mixture as regression for language model pre-training', 'a framework for few-shot evaluation of language models.']
    - Valid Titles: ['regmix: data mixture as regression for language model pre-training']

## Retrieved Tables

### Top 1: `ec6eb433da_table6.csv`

|    Epoch       |    Step    |    Training Loss  |  dim_128_cosine_map@100    |  dim_256_cosine_map@100    |  dim_512_cosine_map@100    |  dim_64_cosine_map@100    |  dim_768_cosine_map@100    |
|---------------:|-----------:|------------------:|:---------------------------|:---------------------------|:---------------------------|:--------------------------|:---------------------------|
|         1.5385 |         10 |            7.981  | -                          | -                          | -                          | -                         | -                          |
|         3.0769 |         20 |            0.9258 | -                          | -                          | -                          | -                         | -                          |
|         4.6154 |         30 |            0.1708 | 0.0285                     | 0.0294                     | 0.0293                     | 0.0302                    | 0.0297                     |
...

**ModelÂ â†’Â Titles**
- **RishuD7/exigent-bge-base-financial-matryoshka**:
    - Raw Titles: ['matryoshka representation learning', 'efficient natural language response suggestion for smart reply', 'state-of-the-art text embeddings', 'sentence-bert: sentence embeddings using siamese bert-networks']
    - Valid Titles: ['matryoshka representation learning', 'efficient natural language response suggestion for smart reply', 'sentence-bert: sentence embeddings using siamese bert-networks']


### Top 2: `ae069fb8b0_table1.csv`

|    Train Loss  |    Train Accuracy  |    Validation Loss  |    Validation Accuracy  |    Epoch  |
|---------------:|-------------------:|--------------------:|------------------------:|----------:|
|         0.2403 |             0.9367 |              0.2023 |                  0.9505 |         0 |
|         0.2233 |             0.9367 |              0.1936 |                  0.9505 |         1 |
|         0.2023 |             0.9373 |              0.2062 |                  0.9465 |         2 |
...

**ModelÂ â†’Â Titles**
- **YakovElm/Qt15Classic_256**:
    - Raw Titles: []
    - Valid Titles: []


### Top 3: `9d7cc2791d_table1.csv`

|  Training Loss    |    Epoch  |    Step  |    Validation Loss  |    Rouge1  |    Rouge2  |    Rougel  |    Rougelsum  |
|:------------------|----------:|---------:|--------------------:|-----------:|-----------:|-----------:|--------------:|
| No log            |      0.67 |        1 |             25.1883 |     0.0242 |     0.0023 |     0.0218 |        0.0241 |
| No log            |      2    |        3 |             23.4392 |     0.0242 |     0.0023 |     0.0218 |        0.0241 |
| No log            |      2.67 |        4 |             22.5166 |     0.0252 |     0.0023 |     0.0229 |        0.0251 |
| No log            |      4    |        6 |             20.6643 |     0.0252 |     0.0023 |     0.0229 |        0.0251 |
| No log            |      4.67 |        7 |             19.7334 |     0.0252 |     0.0023 |     0.0229 |        0.0251 |
...

**ModelÂ â†’Â Titles**
- **RMWeerasinghe/t5-small-finetuned-2048**:
    - Raw Titles: []
    - Valid Titles: []


### Top 4: `7ac59f9978_table1.csv`

|  Training Loss    |    Epoch  |    Step  |    Validation Loss  |    Accuracy  |    F1      |
|:------------------|----------:|---------:|--------------------:|-------------:|-----------:|
| No log            |         1 |      125 |              0.2322 |        0.916 |     0.9164 |
| 0.2717            |         2 |      250 |              0.2064 |        0.922 |     0.9226 |
...

**ModelÂ â†’Â Titles**
- **aya-se/distilbert-base-uncased-finetuned-emotion**:
    - Raw Titles: []
    - Valid Titles: []


### Top 5: `75e50f929e_table1.csv`

|    ID   |  Voice                     |  Gender    |  Play Audio                                             |
|--------:|:---------------------------|:-----------|:--------------------------------------------------------|
|       1 | nsnd-le-chuc               | ðŸ‘¨         | <audio controls src="samples/nsnd-le-chuc.mp3"></audio> |
|       2 | speechify_10               | ðŸ‘©         | <audio controls src="samples/speechify_10.wav"></audio> |
|       3 | atuan                      | ðŸ‘¨         | <audio controls src="samples/atuan.wav"></audio>        |
|       4 | speechify_11               | ðŸ‘©         | <audio controls src="samples/speechify_11.wav"></audio> |
|       5 | cdteam                     | ðŸ‘¨         | <audio controls src="samples/cdteam.wav"></audio>       |
...

**ModelÂ â†’Â Titles**
- **dangvansam/viet-tts**:
    - Raw Titles: ['dangvansam (sam dang) Â· github', 'multi-lingual large voice generation model, providing inference, training and deployment full-stack ability.', 'viettts: an open-source vietnamese text to speech', 'python - nsw package for vietnamese: normalization system to convert numbers, abbreviations, and words that cannot be pronounced into syllables', 'silero vad: pre-trained enterprise-grade voice activity detector']
    - Valid Titles: []


### Top 6: `43adbd6f0b_table1.csv`

|  Training Loss    |    Epoch  |    Step  |    Validation Loss  |    Accuracy  |    F1      |
|:------------------|----------:|---------:|--------------------:|-------------:|-----------:|
| No log            |         1 |      250 |              0.3176 |       0.9025 |     0.9017 |
| 0.544             |         2 |      500 |              0.2263 |       0.919  |     0.919  |
...

**ModelÂ â†’Â Titles**
- **Akhilesh2K4/finetuning-emotion-model**:
    - Raw Titles: []
    - Valid Titles: []


### Top 7: `273233458_table4.csv`

|  Metric                       |    AvgQA  |  AvgMM    |  TextVQA    |  SQA-I    |  GQA    |  DocVQA    |  AI2D    |
|:------------------------------|----------:|:----------|:------------|:----------|:--------|:-----------|:---------|
| Captioning (Avg. of 3)        |       100 | S1.1      | S1.2        | S1.3      | -       | -          | -        |
| VQA (Avg. of 8)               |       300 | S1.1      | S1.2        | S1.3      | -       | -          | -        |
| MME perception score          |       100 | S1.1      | S1.2        | S1.3      | -       | -          | -        |
...

**ModelÂ â†’Â Titles**
- **OpenGVLab/Mono-InternVL-2B**:
    - Raw Titles: ['internvl: scaling up vision foundation models and aligning for generic visual-linguistic tasks', 'open-source evaluation toolkit of large multi-modality models (lmms), support 220+ lmms, 80+ benchmarks', 'mono-internvl: pushing the boundaries of monolithic multimodal large language models with endogenous visual pre-training', 'lmdeploy is a toolkit for compressing, deploying, and serving llms.', 'how far are we to gpt-4v? closing the gap to commercial multimodal models with open-source suites']
    - Valid Titles: ['internvl: scaling up vision foundation models and aligning for generic visual-linguistic tasks', 'mono-internvl: pushing the boundaries of monolithic multimodal large language models with endogenous visual pre-training', 'how far are we to gpt-4v? closing the gap to commercial multimodal models with open-source suites']


### Top 8: `270703187_table8.csv`

|  Probability    |  0.2    |  0.3    |  0.4    |  0.5    |  0.6    |  0.7    |  0.8    |
|:----------------|:--------|:--------|:--------|:--------|:--------|:--------|:--------|
| Pre DPO         |         |         |         |         |         |         |         |
| Post DPO        |         |         |         |         |         |         |         |
| Toxicity Level  | 0.1     | 0.2     | 0.3     | 0.4     | 0.5     |         |         |
| Pre DPO         |         |         |         |         |         |         |         |
| Post DPO        |         |         |         |         |         |         |         |
...

**ModelÂ â†’Â Titles**
- **BatsResearch/aya-23-8b-detox-qlora**:
    - Raw Titles: ['preference tuning for toxicity mitigation generalizes across languages', 'rtp-lx: can llms evaluate toxicity in multilingual scenarios?', 'code for "preference tuning for toxicity mitigation generalizes across languages." paper accepted at findings of emnlp 2024', 'a mechanistic understanding of alignment algorithms: a case study on dpo and toxicity']
    - Valid Titles: ['preference tuning for toxicity mitigation generalizes across languages']
- **BatsResearch/bloom-1b7-detox**:
    - Raw Titles: ['preference tuning for toxicity mitigation generalizes across languages', 'rtp-lx: can llms evaluate toxicity in multilingual scenarios?', 'code for "preference tuning for toxicity mitigation generalizes across languages." paper accepted at findings of emnlp 2024', 'a mechanistic understanding of alignment algorithms: a case study on dpo and toxicity']
    - Valid Titles: ['preference tuning for toxicity mitigation generalizes across languages']
- **BatsResearch/bloom-7b1-detox-qlora**:
    - Raw Titles: ['preference tuning for toxicity mitigation generalizes across languages', 'rtp-lx: can llms evaluate toxicity in multilingual scenarios?', 'code for "preference tuning for toxicity mitigation generalizes across languages." paper accepted at findings of emnlp 2024', 'a mechanistic understanding of alignment algorithms: a case study on dpo and toxicity']
    - Valid Titles: ['preference tuning for toxicity mitigation generalizes across languages']
- **BatsResearch/llama2-7b-detox-qlora**:
    - Raw Titles: ['preference tuning for toxicity mitigation generalizes across languages', 'rtp-lx: can llms evaluate toxicity in multilingual scenarios?', 'code for "preference tuning for toxicity mitigation generalizes across languages." paper accepted at findings of emnlp 2024', 'a mechanistic understanding of alignment algorithms: a case study on dpo and toxicity']
    - Valid Titles: ['preference tuning for toxicity mitigation generalizes across languages']
- **BatsResearch/llama3-8b-detox-qlora**:
    - Raw Titles: ['preference tuning for toxicity mitigation generalizes across languages', 'rtp-lx: can llms evaluate toxicity in multilingual scenarios?', 'code for "preference tuning for toxicity mitigation generalizes across languages." paper accepted at findings of emnlp 2024', 'a mechanistic understanding of alignment algorithms: a case study on dpo and toxicity']
    - Valid Titles: ['preference tuning for toxicity mitigation generalizes across languages']
- **BatsResearch/mGPT-detox**:
    - Raw Titles: ['preference tuning for toxicity mitigation generalizes across languages', 'rtp-lx: can llms evaluate toxicity in multilingual scenarios?', 'code for "preference tuning for toxicity mitigation generalizes across languages." paper accepted at findings of emnlp 2024', 'a mechanistic understanding of alignment algorithms: a case study on dpo and toxicity']
    - Valid Titles: ['preference tuning for toxicity mitigation generalizes across languages']


### Top 9: `270703187_table1.csv`

|  Probability    |  0.2    |  0.3    |  0.4    |  0.5    |  0.6    |  0.7    |  0.8    |
|:----------------|:--------|:--------|:--------|:--------|:--------|:--------|:--------|
| Pre DPO         |         |         |         |         |         |         |         |
| Post DPO        |         |         |         |         |         |         |         |
| Toxicity Level  | 0.2     | 0.3     | 0.4     | 0.5     | 0.6     | 0.7     |         |
| Pre DPO         |         |         |         |         |         |         |         |
| Post DPO        |         |         |         |         |         |         |         |
...

**ModelÂ â†’Â Titles**
- **BatsResearch/aya-23-8b-detox-qlora**:
    - Raw Titles: ['preference tuning for toxicity mitigation generalizes across languages', 'rtp-lx: can llms evaluate toxicity in multilingual scenarios?', 'code for "preference tuning for toxicity mitigation generalizes across languages." paper accepted at findings of emnlp 2024', 'a mechanistic understanding of alignment algorithms: a case study on dpo and toxicity']
    - Valid Titles: ['preference tuning for toxicity mitigation generalizes across languages']
- **BatsResearch/bloom-1b7-detox**:
    - Raw Titles: ['preference tuning for toxicity mitigation generalizes across languages', 'rtp-lx: can llms evaluate toxicity in multilingual scenarios?', 'code for "preference tuning for toxicity mitigation generalizes across languages." paper accepted at findings of emnlp 2024', 'a mechanistic understanding of alignment algorithms: a case study on dpo and toxicity']
    - Valid Titles: ['preference tuning for toxicity mitigation generalizes across languages']
- **BatsResearch/bloom-7b1-detox-qlora**:
    - Raw Titles: ['preference tuning for toxicity mitigation generalizes across languages', 'rtp-lx: can llms evaluate toxicity in multilingual scenarios?', 'code for "preference tuning for toxicity mitigation generalizes across languages." paper accepted at findings of emnlp 2024', 'a mechanistic understanding of alignment algorithms: a case study on dpo and toxicity']
    - Valid Titles: ['preference tuning for toxicity mitigation generalizes across languages']
- **BatsResearch/llama2-7b-detox-qlora**:
    - Raw Titles: ['preference tuning for toxicity mitigation generalizes across languages', 'rtp-lx: can llms evaluate toxicity in multilingual scenarios?', 'code for "preference tuning for toxicity mitigation generalizes across languages." paper accepted at findings of emnlp 2024', 'a mechanistic understanding of alignment algorithms: a case study on dpo and toxicity']
    - Valid Titles: ['preference tuning for toxicity mitigation generalizes across languages']
- **BatsResearch/llama3-8b-detox-qlora**:
    - Raw Titles: ['preference tuning for toxicity mitigation generalizes across languages', 'rtp-lx: can llms evaluate toxicity in multilingual scenarios?', 'code for "preference tuning for toxicity mitigation generalizes across languages." paper accepted at findings of emnlp 2024', 'a mechanistic understanding of alignment algorithms: a case study on dpo and toxicity']
    - Valid Titles: ['preference tuning for toxicity mitigation generalizes across languages']
- **BatsResearch/mGPT-detox**:
    - Raw Titles: ['preference tuning for toxicity mitigation generalizes across languages', 'rtp-lx: can llms evaluate toxicity in multilingual scenarios?', 'code for "preference tuning for toxicity mitigation generalizes across languages." paper accepted at findings of emnlp 2024', 'a mechanistic understanding of alignment algorithms: a case study on dpo and toxicity']
    - Valid Titles: ['preference tuning for toxicity mitigation generalizes across languages']



---

# Query Table: `6bf92014bf_table1.csv`

## Query Table Content

|    Training Loss  |    Epoch  |    Step  |    Validation Loss  |
|------------------:|----------:|---------:|--------------------:|
|            6.4679 |      0.09 |       10 |              2.3771 |
|            0.7781 |      0.18 |       20 |              0.1824 |
|            0.1615 |      0.27 |       30 |              0.1619 |
|            0.154  |      0.36 |       40 |              0.1545 |
|            0.1511 |      0.45 |       50 |              0.1506 |
...

**Query Table Model â†’ Titles**
- **Litzy619/O0508B1**:
    - Raw Titles: []
    - Valid Titles: []

## Retrieved Tables

### Top 1: `7b574407e3_table1.csv`

|    Training Loss  |    Epoch  |    Step  |    Validation Loss  |
|------------------:|----------:|---------:|--------------------:|
|            2.496  |      0.09 |       10 |              0.2654 |
|            0.1748 |      0.18 |       20 |              0.1591 |
|            0.1491 |      0.27 |       30 |              0.1619 |
|            0.155  |      0.36 |       40 |              0.1582 |
|            0.1505 |      0.45 |       50 |              0.1492 |
...

**ModelÂ â†’Â Titles**
- **Litzy619/O0503HMA6**:
    - Raw Titles: []
    - Valid Titles: []


### Top 2: `87584414da_table1.csv`

|    Training Loss  |    Epoch  |    Step  |    Validation Loss  |
|------------------:|----------:|---------:|--------------------:|
|            4.5593 |      0.09 |       10 |              1.0148 |
|            0.3007 |      0.17 |       20 |              0.1582 |
|            0.1628 |      0.26 |       30 |              0.1506 |
|            0.154  |      0.34 |       40 |              0.1545 |
|            0.152  |      0.43 |       50 |              0.1497 |
...

**ModelÂ â†’Â Titles**
- **Litzy619/V0305O5**:
    - Raw Titles: []
    - Valid Titles: []


### Top 3: `b2a3e55083_table1.csv`

|    Training Loss  |    Epoch  |    Step  |    Validation Loss  |
|------------------:|----------:|---------:|--------------------:|
|            3.2491 |      0.09 |       10 |              1.4949 |
|            0.7419 |      0.18 |       20 |              0.2008 |
|            0.1742 |      0.27 |       30 |              0.1637 |
|            0.1554 |      0.36 |       40 |              0.1571 |
|            0.1519 |      0.45 |       50 |              0.1515 |
...

**ModelÂ â†’Â Titles**
- **Litzy619/O0513MA**:
    - Raw Titles: []
    - Valid Titles: []


### Top 4: `d1f187a2a7_table1.csv`

|    Training Loss  |    Epoch  |    Step  |    Validation Loss  |
|------------------:|----------:|---------:|--------------------:|
|            4.9313 |      0.09 |       10 |              2.2642 |
|            0.7787 |      0.18 |       20 |              0.1738 |
|            0.1559 |      0.27 |       30 |              0.1586 |
|            0.1548 |      0.36 |       40 |              0.1529 |
|            0.1516 |      0.45 |       50 |              0.1509 |
...

**ModelÂ â†’Â Titles**
- **Litzy619/O0508V8**:
    - Raw Titles: []
    - Valid Titles: []


### Top 5: `e650c0901c_table1.csv`

|    Training Loss  |    Epoch  |    Step  |    Validation Loss  |
|------------------:|----------:|---------:|--------------------:|
|            4.9741 |      0.09 |       10 |              2.4095 |
|            0.8967 |      0.18 |       20 |              0.1948 |
|            0.1642 |      0.27 |       30 |              0.1564 |
|            0.1516 |      0.36 |       40 |              0.154  |
|            0.1514 |      0.45 |       50 |              0.1499 |
...

**ModelÂ â†’Â Titles**
- **Litzy619/O0508V7**:
    - Raw Titles: []
    - Valid Titles: []


### Top 6: `9c370803ca_table1.csv`

|    Training Loss  |    Epoch  |    Step  |    Validation Loss  |
|------------------:|----------:|---------:|--------------------:|
|            2.4638 |      0.09 |       10 |              1.3793 |
|            0.7418 |      0.18 |       20 |              0.2028 |
|            0.1674 |      0.27 |       30 |              0.1537 |
|            0.1515 |      0.36 |       40 |              0.1513 |
|            0.1467 |      0.45 |       50 |              0.1468 |
...


### Top 7: `bbbbdbaf2d_table1.csv`

|    Training Loss  |    Epoch  |    Step  |    Validation Loss  |
|------------------:|----------:|---------:|--------------------:|
|            2.4638 |      0.09 |       10 |              1.3793 |
|            0.7418 |      0.18 |       20 |              0.2028 |
|            0.1674 |      0.27 |       30 |              0.1537 |
|            0.1515 |      0.36 |       40 |              0.1513 |
|            0.1467 |      0.45 |       50 |              0.1468 |
...


### Top 8: `7174efa888_table1.csv`

|    Training Loss  |    Epoch  |    Step  |    Validation Loss  |
|------------------:|----------:|---------:|--------------------:|
|            4.819  |      0.09 |       10 |              1.4638 |
|            0.4886 |      0.18 |       20 |              0.2184 |
|            0.1649 |      0.27 |       30 |              0.1599 |
|            0.154  |      0.36 |       40 |              0.1524 |
|            0.1498 |      0.45 |       50 |              0.1531 |
...

**ModelÂ â†’Â Titles**
- **Litzy619/O0507TESTV1**:
    - Raw Titles: []
    - Valid Titles: []


### Top 9: `ea8af179bd_table1.csv`

|    Training Loss  |    Epoch  |    Step  |    Validation Loss  |
|------------------:|----------:|---------:|--------------------:|
|            2.8711 |      0.09 |       10 |              0.217  |
|            0.1732 |      0.18 |       20 |              0.1549 |
|            0.1487 |      0.27 |       30 |              0.1676 |
|            0.156  |      0.36 |       40 |              0.1536 |
|            0.152  |      0.45 |       50 |              0.1517 |
...

**ModelÂ â†’Â Titles**
- **Litzy619/O0503HMA8**:
    - Raw Titles: []
    - Valid Titles: []



---

# Query Table: `b27bde91d7_table1.csv`

## Query Table Content

|  Link                                                                                                     |  Type    |    Size/GB  |  Notes     |
|:----------------------------------------------------------------------------------------------------------|:---------|------------:|:-----------|
| [GGUF](https://huggingface.co/mradermacher/Llama-3-8B-NOLA-GGUF/resolve/main/Llama-3-8B-NOLA.Q2_K.gguf)   | Q2_K     |         3.3 |            |
| [GGUF](https://huggingface.co/mradermacher/Llama-3-8B-NOLA-GGUF/resolve/main/Llama-3-8B-NOLA.IQ3_XS.gguf) | IQ3_XS   |         3.6 |            |
| [GGUF](https://huggingface.co/mradermacher/Llama-3-8B-NOLA-GGUF/resolve/main/Llama-3-8B-NOLA.Q3_K_S.gguf) | Q3_K_S   |         3.8 |            |
| [GGUF](https://huggingface.co/mradermacher/Llama-3-8B-NOLA-GGUF/resolve/main/Llama-3-8B-NOLA.IQ3_S.gguf)  | IQ3_S    |         3.8 | beats Q3_K |
| [GGUF](https://huggingface.co/mradermacher/Llama-3-8B-NOLA-GGUF/resolve/main/Llama-3-8B-NOLA.IQ3_M.gguf)  | IQ3_M    |         3.9 |            |
...

**Query Table Model â†’ Titles**
- **mradermacher/Llama-3-8B-NOLA-GGUF**:
    - Raw Titles: ['gguf quantizations overview Â· github']
    - Valid Titles: []

## Retrieved Tables

### Top 1: `889a845e5c_table1.csv`

|  Link                                                                                                               |  Type    |    Size/GB  |  Notes     |
|:--------------------------------------------------------------------------------------------------------------------|:---------|------------:|:-----------|
| [GGUF](https://huggingface.co/mradermacher/Llama-3-8B-ASN-alpha-GGUF/resolve/main/Llama-3-8B-ASN-alpha.Q2_K.gguf)   | Q2_K     |         3.3 |            |
| [GGUF](https://huggingface.co/mradermacher/Llama-3-8B-ASN-alpha-GGUF/resolve/main/Llama-3-8B-ASN-alpha.IQ3_XS.gguf) | IQ3_XS   |         3.6 |            |
| [GGUF](https://huggingface.co/mradermacher/Llama-3-8B-ASN-alpha-GGUF/resolve/main/Llama-3-8B-ASN-alpha.Q3_K_S.gguf) | Q3_K_S   |         3.8 |            |
| [GGUF](https://huggingface.co/mradermacher/Llama-3-8B-ASN-alpha-GGUF/resolve/main/Llama-3-8B-ASN-alpha.IQ3_S.gguf)  | IQ3_S    |         3.8 | beats Q3_K |
| [GGUF](https://huggingface.co/mradermacher/Llama-3-8B-ASN-alpha-GGUF/resolve/main/Llama-3-8B-ASN-alpha.IQ3_M.gguf)  | IQ3_M    |         3.9 |            |
...

**ModelÂ â†’Â Titles**
- **mradermacher/Llama-3-8B-ASN-alpha-GGUF**:
    - Raw Titles: ['gguf quantizations overview Â· github']
    - Valid Titles: []


### Top 2: `a21e4328c2_table1.csv`

|  Link                                                                                                                 |  Type    |    Size/GB  |  Notes     |
|:----------------------------------------------------------------------------------------------------------------------|:---------|------------:|:-----------|
| [GGUF](https://huggingface.co/mradermacher/Llama-3-8B-Irene-v0.3-GGUF/resolve/main/Llama-3-8B-Irene-v0.3.Q2_K.gguf)   | Q2_K     |         3.3 |            |
| [GGUF](https://huggingface.co/mradermacher/Llama-3-8B-Irene-v0.3-GGUF/resolve/main/Llama-3-8B-Irene-v0.3.IQ3_XS.gguf) | IQ3_XS   |         3.6 |            |
| [GGUF](https://huggingface.co/mradermacher/Llama-3-8B-Irene-v0.3-GGUF/resolve/main/Llama-3-8B-Irene-v0.3.Q3_K_S.gguf) | Q3_K_S   |         3.8 |            |
| [GGUF](https://huggingface.co/mradermacher/Llama-3-8B-Irene-v0.3-GGUF/resolve/main/Llama-3-8B-Irene-v0.3.IQ3_S.gguf)  | IQ3_S    |         3.8 | beats Q3_K |
| [GGUF](https://huggingface.co/mradermacher/Llama-3-8B-Irene-v0.3-GGUF/resolve/main/Llama-3-8B-Irene-v0.3.IQ3_M.gguf)  | IQ3_M    |         3.9 |            |
...

**ModelÂ â†’Â Titles**
- **mradermacher/Llama-3-8B-Irene-v0.3-GGUF**:
    - Raw Titles: ['gguf quantizations overview Â· github']
    - Valid Titles: []


### Top 3: `95f51f9e10_table1.csv`

|  Link                                                                                                                 |  Type    |    Size/GB  |  Notes     |
|:----------------------------------------------------------------------------------------------------------------------|:---------|------------:|:-----------|
| [GGUF](https://huggingface.co/mradermacher/Llama-3-8B-Irene-v0.1-GGUF/resolve/main/Llama-3-8B-Irene-v0.1.Q2_K.gguf)   | Q2_K     |         3.3 |            |
| [GGUF](https://huggingface.co/mradermacher/Llama-3-8B-Irene-v0.1-GGUF/resolve/main/Llama-3-8B-Irene-v0.1.IQ3_XS.gguf) | IQ3_XS   |         3.6 |            |
| [GGUF](https://huggingface.co/mradermacher/Llama-3-8B-Irene-v0.1-GGUF/resolve/main/Llama-3-8B-Irene-v0.1.Q3_K_S.gguf) | Q3_K_S   |         3.8 |            |
| [GGUF](https://huggingface.co/mradermacher/Llama-3-8B-Irene-v0.1-GGUF/resolve/main/Llama-3-8B-Irene-v0.1.IQ3_S.gguf)  | IQ3_S    |         3.8 | beats Q3_K |
| [GGUF](https://huggingface.co/mradermacher/Llama-3-8B-Irene-v0.1-GGUF/resolve/main/Llama-3-8B-Irene-v0.1.IQ3_M.gguf)  | IQ3_M    |         3.9 |            |
...

**ModelÂ â†’Â Titles**
- **mradermacher/Llama-3-8B-Irene-v0.1-GGUF**:
    - Raw Titles: ['gguf quantizations overview Â· github']
    - Valid Titles: []


### Top 4: `1fcee79eab_table1.csv`

|  Link                                                                                                   |  Type    |    Size/GB  |  Notes     |
|:--------------------------------------------------------------------------------------------------------|:---------|------------:|:-----------|
| [GGUF](https://huggingface.co/mradermacher/Llama-3-8B-RMU-GGUF/resolve/main/Llama-3-8B-RMU.Q2_K.gguf)   | Q2_K     |         3.3 |            |
| [GGUF](https://huggingface.co/mradermacher/Llama-3-8B-RMU-GGUF/resolve/main/Llama-3-8B-RMU.IQ3_XS.gguf) | IQ3_XS   |         3.6 |            |
| [GGUF](https://huggingface.co/mradermacher/Llama-3-8B-RMU-GGUF/resolve/main/Llama-3-8B-RMU.Q3_K_S.gguf) | Q3_K_S   |         3.8 |            |
| [GGUF](https://huggingface.co/mradermacher/Llama-3-8B-RMU-GGUF/resolve/main/Llama-3-8B-RMU.IQ3_S.gguf)  | IQ3_S    |         3.8 | beats Q3_K |
| [GGUF](https://huggingface.co/mradermacher/Llama-3-8B-RMU-GGUF/resolve/main/Llama-3-8B-RMU.IQ3_M.gguf)  | IQ3_M    |         3.9 |            |
...

**ModelÂ â†’Â Titles**
- **mradermacher/Llama-3-8B-RMU-GGUF**:
    - Raw Titles: ['gguf quantizations overview Â· github']
    - Valid Titles: []


### Top 5: `fa4779f6f5_table1.csv`

|  Link                                                                                                         |  Type    |    Size/GB  |  Notes     |
|:--------------------------------------------------------------------------------------------------------------|:---------|------------:|:-----------|
| [GGUF](https://huggingface.co/mradermacher/Llama-3-8B-claude-GGUF/resolve/main/Llama-3-8B-claude.Q2_K.gguf)   | Q2_K     |         3.3 |            |
| [GGUF](https://huggingface.co/mradermacher/Llama-3-8B-claude-GGUF/resolve/main/Llama-3-8B-claude.IQ3_XS.gguf) | IQ3_XS   |         3.6 |            |
| [GGUF](https://huggingface.co/mradermacher/Llama-3-8B-claude-GGUF/resolve/main/Llama-3-8B-claude.Q3_K_S.gguf) | Q3_K_S   |         3.8 |            |
| [GGUF](https://huggingface.co/mradermacher/Llama-3-8B-claude-GGUF/resolve/main/Llama-3-8B-claude.IQ3_S.gguf)  | IQ3_S    |         3.8 | beats Q3_K |
| [GGUF](https://huggingface.co/mradermacher/Llama-3-8B-claude-GGUF/resolve/main/Llama-3-8B-claude.IQ3_M.gguf)  | IQ3_M    |         3.9 |            |
...

**ModelÂ â†’Â Titles**
- **mradermacher/Llama-3-8B-claude-GGUF**:
    - Raw Titles: ['gguf quantizations overview Â· github']
    - Valid Titles: []


### Top 6: `5ddfd5cf89_table1.csv`

|  Link                                                                                                                       |  Type    |    Size/GB  |  Notes     |
|:----------------------------------------------------------------------------------------------------------------------------|:---------|------------:|:-----------|
| [GGUF](https://huggingface.co/mradermacher/Llama-3-8B-ShareGPT-112K-GGUF/resolve/main/Llama-3-8B-ShareGPT-112K.Q2_K.gguf)   | Q2_K     |         3.3 |            |
| [GGUF](https://huggingface.co/mradermacher/Llama-3-8B-ShareGPT-112K-GGUF/resolve/main/Llama-3-8B-ShareGPT-112K.IQ3_XS.gguf) | IQ3_XS   |         3.6 |            |
| [GGUF](https://huggingface.co/mradermacher/Llama-3-8B-ShareGPT-112K-GGUF/resolve/main/Llama-3-8B-ShareGPT-112K.Q3_K_S.gguf) | Q3_K_S   |         3.8 |            |
| [GGUF](https://huggingface.co/mradermacher/Llama-3-8B-ShareGPT-112K-GGUF/resolve/main/Llama-3-8B-ShareGPT-112K.IQ3_S.gguf)  | IQ3_S    |         3.8 | beats Q3_K |
| [GGUF](https://huggingface.co/mradermacher/Llama-3-8B-ShareGPT-112K-GGUF/resolve/main/Llama-3-8B-ShareGPT-112K.IQ3_M.gguf)  | IQ3_M    |         3.9 |            |
...

**ModelÂ â†’Â Titles**
- **mradermacher/Llama-3-8B-ShareGPT-112K-GGUF**:
    - Raw Titles: ['gguf quantizations overview Â· github']
    - Valid Titles: []


### Top 7: `8a86029fc8_table1.csv`

|  Link                                                                                                                 |  Type    |    Size/GB  |  Notes     |
|:----------------------------------------------------------------------------------------------------------------------|:---------|------------:|:-----------|
| [GGUF](https://huggingface.co/mradermacher/Llama-3-8B-shisa-2x8B-GGUF/resolve/main/Llama-3-8B-shisa-2x8B.Q2_K.gguf)   | Q2_K     |         5.3 |            |
| [GGUF](https://huggingface.co/mradermacher/Llama-3-8B-shisa-2x8B-GGUF/resolve/main/Llama-3-8B-shisa-2x8B.IQ3_XS.gguf) | IQ3_XS   |         5.9 |            |
| [GGUF](https://huggingface.co/mradermacher/Llama-3-8B-shisa-2x8B-GGUF/resolve/main/Llama-3-8B-shisa-2x8B.Q3_K_S.gguf) | Q3_K_S   |         6.2 |            |
| [GGUF](https://huggingface.co/mradermacher/Llama-3-8B-shisa-2x8B-GGUF/resolve/main/Llama-3-8B-shisa-2x8B.IQ3_S.gguf)  | IQ3_S    |         6.2 | beats Q3_K |
| [GGUF](https://huggingface.co/mradermacher/Llama-3-8B-shisa-2x8B-GGUF/resolve/main/Llama-3-8B-shisa-2x8B.IQ3_M.gguf)  | IQ3_M    |         6.3 |            |
...

**ModelÂ â†’Â Titles**
- **mradermacher/Llama-3-8B-shisa-2x8B-GGUF**:
    - Raw Titles: ['gguf quantizations overview Â· github']
    - Valid Titles: []



---

# Query Table: `f6e5b04f86_table1.csv`

## Query Table Content

|  testset                  |    BLEU   |    chr-F  |
|:--------------------------|----------:|----------:|
| Tatoeba-test.ukr.cat      |      33.7 |     0.538 |
...

**Query Table Model â†’ Titles**
- **Helsinki-NLP/opus-mt-uk-ca**:
    - Raw Titles: []
    - Valid Titles: []

## Retrieved Tables

### Top 1: `5d12f47b7e_table1.csv`

|  testset                  |    BLEU   |    chr-F  |
|:--------------------------|----------:|----------:|
| Tatoeba-test.deu.nor      |      33.2 |     0.554 |
...

**ModelÂ â†’Â Titles**
- **Helsinki-NLP/opus-mt-de-no**:
    - Raw Titles: []
    - Valid Titles: []


### Top 2: `3e6e6d9a6ceb84d9a47c358bae3bb52e_table_0.csv`

|  testset                  |    BLEU   |    chr-F  |
|:--------------------------|----------:|----------:|
| Tatoeba-test.deu.nor      |      33.2 |     0.554 |
...


### Top 3: `a872ebb8fa_table1.csv`

|  testset                  |    BLEU   |    chr-F  |
|:--------------------------|----------:|----------:|
| Tatoeba-test.spa.vie      |      33.1 |     0.508 |
...

**ModelÂ â†’Â Titles**
- **Helsinki-NLP/opus-mt-es-vi**:
    - Raw Titles: []
    - Valid Titles: []


### Top 4: `892364c76d_table1.csv`

|  testset                  |    BLEU   |    chr-F  |
|:--------------------------|----------:|----------:|
| JW300.fr.war              |      33.7 |     0.538 |
...

**ModelÂ â†’Â Titles**
- **Helsinki-NLP/opus-mt-fr-war**:
    - Raw Titles: []
    - Valid Titles: []


### Top 5: `b772976393_table1.csv`

|  testset                  |    BLEU   |    chr-F  |
|:--------------------------|----------:|----------:|
| Tatoeba-test.slv.rus      |      37.3 |     0.504 |
...

**ModelÂ â†’Â Titles**
- **Helsinki-NLP/opus-mt-sl-ru**:
    - Raw Titles: []
    - Valid Titles: []


### Top 6: `edb3c297c8b7244d6fed7052a9437c9e_table_0.csv`

|  testset                  |    BLEU   |    chr-F  |
|:--------------------------|----------:|----------:|
| Tatoeba-test.spa.tgl      |      24.7 |     0.538 |
...


### Top 7: `89c9c0d9b2_table1.csv`

|  testset                  |    BLEU   |    chr-F  |
|:--------------------------|----------:|----------:|
| Tatoeba-test.spa.tgl      |      24.7 |     0.538 |
...

**ModelÂ â†’Â Titles**
- **Helsinki-NLP/opus-mt-es-tl**:
    - Raw Titles: []
    - Valid Titles: []



---

# Query Table: `0f857b0eb7_table1.csv`

## Query Table Content

| Unnamed: 1           |                   | NatSight-AdpSeq2Seq (BART-base)    |  .1               |
|:---------------------|:------------------|:-----------------------------------|:------------------|
| nan                  | Dev               | nan                                | Test              |
| Acc-(Logical form) % | Acc-(Execution) % | Acc-(Logical form) %               | Acc-(Execution) % |
| 83.38                | 87.83             | 84                                 | 86.39             |
...

**Query Table Model â†’ Titles**
- **C5i/NatSight-bart-base-wikisql**:
    - Raw Titles: ['natsight: a framework for building domain agnostic natural language interface to databases for next-gen augmented analytics']
    - Valid Titles: ['natsight: a framework for building domain agnostic natural language interface to databases for next-gen augmented analytics']

## Retrieved Tables

### Top 1: `67e5c939bb_table1.csv`

| Unnamed: 1           |  NatSight-AdpSeq2Seq (T5-small)    |                      |  .1               |
|:---------------------|:-----------------------------------|:---------------------|:------------------|
| nan                  | Dev                                | nan                  | Test              |
| Acc-(Logical form) % | Acc-(Execution) %                  | Acc-(Logical form) % | Acc-(Execution) % |
| 82.31                | 85.7                               | 83.5                 | 85.38             |
...

**ModelÂ â†’Â Titles**
- **C5i/NatSight-t5-small-wikisql**:
    - Raw Titles: ['natsight: a framework for building domain agnostic natural language interface to databases for next-gen augmented analytics']
    - Valid Titles: ['natsight: a framework for building domain agnostic natural language interface to databases for next-gen augmented analytics']


### Top 2: `dda508d8e0_table1.csv`

|  Metric                   |    Value                      |
|:--------------------------|------------------------------:|
| Avg.                      |                         54.53 |
| ARC (25-shot)             |                         62.29 |
| HellaSwag (10-shot)       |                         82.46 |
| MMLU (5-shot)             |                         57.09 |
| TruthfulQA (0-shot)       |                         51.41 |
...

**ModelÂ â†’Â Titles**
- **Weyaxi/Stable-Platypus2-13B-QLoRA-0.80-epoch**:
    - Raw Titles: []
    - Valid Titles: []


### Top 3: `dcd37f549a_table1.csv`

|  Metric                   |    Value                      |
|:--------------------------|------------------------------:|
| Avg.                      |                         42.5  |
| ARC (25-shot)             |                         38.82 |
| HellaSwag (10-shot)       |                         72.76 |
| MMLU (5-shot)             |                         23.12 |
| TruthfulQA (0-shot)       |                         46.92 |
...

**ModelÂ â†’Â Titles**
- **vibhorag101/llama-2-13b-chat-hf-phr_mental_therapy**:
    - Raw Titles: []
    - Valid Titles: []


### Top 4: `91249257c7_table1.csv`

|  Model          |    MRR@10  |     Recall@50  |    Recall@1k  |
|:----------------|-----------:|---------------:|--------------:|
| ColBERTv2       |       39.7 |           86.8 |          97.6 |
| Jina-ColBERT-v1 |       39   |           85.6 |          96.2 |
...

**ModelÂ â†’Â Titles**
- **jinaai/jina-colbert-v1-en**:
    - Raw Titles: ['evaluate rerankers', 'jina embeddings 2: 8192-token general-purpose text embeddings for long documents', 'colbertv2: effective and efficient retrieval via lightweight late interaction', 'train short, test long: attention with linear biases enables input length extrapolation', "colbert: state-of-the-art neural search (sigir'20, tacl'21, neurips'21, naacl'22, cikm'22, acl'23, emnlp'23)", 'colbert: efficient and effective passage search via contextualized late interaction over bert']
    - Valid Titles: ['colbertv2: effective and efficient retrieval via lightweight late interaction', 'colbert: efficient and effective passage search via contextualized late interaction over bert']


### Top 5: `722d5e3e61_table1.csv`

|        |      eval_f1_micro  |      eval_recall_micro  |      eval_precision_micro  |      eval_f1_macro  |      eval_recall_macro  |      eval_precision_macro  |      eval_accuracy  |
|-------:|--------------------:|------------------------:|---------------------------:|--------------------:|------------------------:|---------------------------:|--------------------:|
|      0 |               84.39 |                   84.39 |                      84.39 |               84.42 |                   84.39 |                      84.61 |               84.39 |
...

**ModelÂ â†’Â Titles**
- **vocabtrimmer/xlm-v-base-xnli-en**:
    - Raw Titles: []
    - Valid Titles: []


### Top 6: `543ab2b8ed_table2.csv`

|  Model                                                                            |  Language    |    PR AUC (%)     |    ROC AUC (%)        |    Accuracy (%)        |    F1-score (%)     |
|:----------------------------------------------------------------------------------|:-------------|------------------:|----------------------:|-----------------------:|--------------------:|
| [Bloomz-560m-guardrail](https://huggingface.co/cmarkea/bloomz-560m-guardrail)     | French       |                77 |                    85 |                     78 |                  60 |
| [Bloomz-560m-guardrail](https://huggingface.co/cmarkea/bloomz-560m-guardrail)     | English      |                77 |                    84 |                     79 |                  62 |
| [Bloomz-3b-guardrail](https://huggingface.co/cmarkea/bloomz-3b-guardrail)         | French       |                82 |                    89 |                     84 |                  72 |
| [Bloomz-3b-guardrail](https://huggingface.co/cmarkea/bloomz-3b-guardrail)         | English      |                80 |                    88 |                     82 |                  70 |
...

**ModelÂ â†’Â Titles**
- **cmarkea/bloomz-3b-guardrail**:
    - Raw Titles: []
    - Valid Titles: []
- **cmarkea/bloomz-560m-guardrail**:
    - Raw Titles: []
    - Valid Titles: []


### Top 7: `4f29377cb3_table1.csv`

|  Metric                   |    Value                      |
|:--------------------------|------------------------------:|
| Avg.                      |                         34.19 |
| ARC (25-shot)             |                         38.74 |
| HellaSwag (10-shot)       |                         66.83 |
| MMLU (5-shot)             |                         26.57 |
| TruthfulQA (0-shot)       |                         36.54 |
...

**ModelÂ â†’Â Titles**
- **KnutJaegersberg/black_goo_recipe_c**:
    - Raw Titles: []
    - Valid Titles: []


### Top 8: `405b2d47da_table1.csv`

|    GOLD 1         |    GOLD 2         |    FLORES   |    TEST-SUITE |   Unnamed: 5 |
|------------------:|------------------:|------------:|--------------:|-------------:|
|              79.5 |              43.5 |        21.4 |          73.4 |          nan |
...

**ModelÂ â†’Â Titles**
- **proxectonos/Nos_MT-OpenNMT-es-gl**:
    - Raw Titles: ['fast inference engine for transformer models', 'corpus de texto ou voz en galego (monolingÃ¼es e multilingÃ¼es) para diferentes tarefas pln/ monolingual and multilingual text and voice corpora in galician for different nlp tasks.', 'multilingual toolkit for nlp: dependency parser, pos tagger, nerc, multiword extractor, sentiment analysis, etc.']
    - Valid Titles: []


### Top 9: `2010.12821_table12.csv`

| English             | # PT params   | # FT params   |   nan |   MNLI |
|:--------------------|:--------------|:--------------|------:|-------:|
| E=H=768ð¸ð»768E=H=768 | 110M          | 110M          |   nan |   84.5 |
| E=H=128ð¸ð»128E=H=128 | 89M           | 89M           |   nan |   83.7 |
...



---

# Query Table: `5cd5d7b9c7_table1.csv`

## Query Table Content

|    Training Loss  |    Epoch  |    Step  |    Validation Loss  |    F1      |
|------------------:|----------:|---------:|--------------------:|-----------:|
|            0.2525 |         1 |      525 |              0.1673 |     0.8294 |
|            0.1298 |         2 |     1050 |              0.1381 |     0.851  |
|            0.0839 |         3 |     1575 |              0.1356 |     0.86   |
...

**Query Table Model â†’ Titles**
- **coolzhao/xlm-roberta-base-finetuned-panx-de**:
    - Raw Titles: []
    - Valid Titles: []
- **xrverse/xlm-roberta-base-finetuned-panx-de**:
    - Raw Titles: []
    - Valid Titles: []

## Retrieved Tables

### Top 1: `cc952dd4c9_table1.csv`

|    Training Loss  |    Epoch  |    Step  |    Validation Loss  |    F1      |
|------------------:|----------:|---------:|--------------------:|-----------:|
|            0.2575 |         1 |      525 |              0.1621 |     0.8292 |
|            0.1287 |         2 |     1050 |              0.1378 |     0.8526 |
|            0.0831 |         3 |     1575 |              0.1372 |     0.8621 |
...


### Top 2: `9d620bc6e4_table1.csv`

|    Training Loss  |    Epoch  |    Step  |    Validation Loss  |    F1      |
|------------------:|----------:|---------:|--------------------:|-----------:|
|            0.2575 |         1 |      525 |              0.1621 |     0.8292 |
|            0.1287 |         2 |     1050 |              0.1378 |     0.8526 |
|            0.0831 |         3 |     1575 |              0.1372 |     0.8621 |
...


### Top 3: `4261915808_table1.csv`

|    Training Loss  |    Epoch  |    Step  |    Validation Loss  |    F1      |
|------------------:|----------:|---------:|--------------------:|-----------:|
|            0.2575 |         1 |      525 |              0.1621 |     0.8292 |
|            0.1287 |         2 |     1050 |              0.1378 |     0.8526 |
|            0.0831 |         3 |     1575 |              0.1372 |     0.8621 |
...


### Top 4: `0da501760f_table1.csv`

|    Training Loss  |    Epoch  |    Step  |    Validation Loss  |    F1 Score  |
|------------------:|----------:|---------:|--------------------:|-------------:|
|            0.2575 |         1 |      525 |              0.1621 |       0.8292 |
|            0.1287 |         2 |     1050 |              0.1378 |       0.8526 |
|            0.0831 |         3 |     1575 |              0.1372 |       0.8621 |
...

**ModelÂ â†’Â Titles**
- **moghis/xlm-roberta-base-finetuned-panx-de-data**:
    - Raw Titles: []
    - Valid Titles: []


### Top 5: `a80e8e1221_table1.csv`

|    Training Loss  |    Epoch  |    Step  |    Validation Loss  |    F1      |
|------------------:|----------:|---------:|--------------------:|-----------:|
|            0.2553 |         1 |      525 |              0.1496 |     0.8277 |
|            0.1299 |         2 |     1050 |              0.1324 |     0.8475 |
|            0.0833 |         3 |     1575 |              0.1382 |     0.8614 |
...

**ModelÂ â†’Â Titles**
- **nitin1690/xlm-roberta-base-finetuned-panx-de**:
    - Raw Titles: []
    - Valid Titles: []


### Top 6: `41e342eda4_table1.csv`

|    Training Loss  |    Epoch  |    Step  |    Validation Loss  |    F1      |
|------------------:|----------:|---------:|--------------------:|-----------:|
|            0.2582 |         1 |      525 |              0.1596 |     0.8185 |
|            0.1292 |         2 |     1050 |              0.1374 |     0.8424 |
|            0.0826 |         3 |     1575 |              0.1351 |     0.8601 |
...

**ModelÂ â†’Â Titles**
- **khalidr/xlm-roberta-base-finetuned-panx-de**:
    - Raw Titles: []
    - Valid Titles: []


### Top 7: `2c12d7c024_table1.csv`

|    Training Loss  |    Epoch  |    Step  |    Validation Loss  |    F1      |
|------------------:|----------:|---------:|--------------------:|-----------:|
|            0.2577 |         1 |      525 |              0.1668 |     0.8145 |
|            0.1285 |         2 |     1050 |              0.1376 |     0.8495 |
|            0.0812 |         3 |     1575 |              0.1377 |     0.8617 |
...

**ModelÂ â†’Â Titles**
- **timmartin/xlm-roberta-base-finetuned-panx-de**:
    - Raw Titles: []
    - Valid Titles: []


### Top 8: `32a5bad191_table1.csv`

|    Training Loss  |    Epoch  |    Step  |    Validation Loss  |    F1      |
|------------------:|----------:|---------:|--------------------:|-----------:|
|            0.2573 |         1 |      525 |              0.1651 |     0.8199 |
|            0.1296 |         2 |     1050 |              0.1482 |     0.8413 |
|            0.081  |         3 |     1575 |              0.1377 |     0.8605 |
...

**ModelÂ â†’Â Titles**
- **leixu/xlm-roberta-base-finetuned-panx-de**:
    - Raw Titles: []
    - Valid Titles: []


### Top 9: `28929a6e76_table1.csv`

|    Training Loss  |    Epoch  |    Step  |    Validation Loss  |    F1      |
|------------------:|----------:|---------:|--------------------:|-----------:|
|            0.2602 |         1 |      525 |              0.1633 |     0.8254 |
|            0.1297 |         2 |     1050 |              0.1377 |     0.8435 |
|            0.0807 |         3 |     1575 |              0.1359 |     0.8622 |
...

**ModelÂ â†’Â Titles**
- **kevin-allen/xlm-roberta-base-finetuned-panx-de**:
    - Raw Titles: []
    - Valid Titles: []



---

# Query Table: `598f4183b3_table1.csv`

## Query Table Content

|    Training Loss  |    Epoch  |    Step  |    Validation Loss  |
|------------------:|----------:|---------:|--------------------:|
|            2.6767 |         1 |      157 |              2.5083 |
|            2.5718 |         2 |      314 |              2.449  |
|            2.5325 |         3 |      471 |              2.4457 |
...

**Query Table Model â†’ Titles**
- **kevin-py/distilbert-base-uncased-finetuned-imdb**:
    - Raw Titles: []
    - Valid Titles: []

## Retrieved Tables

### Top 1: `75af9fe2c1_table1.csv`

|    Training Loss  |    Epoch  |    Step  |    Validation Loss  |
|------------------:|----------:|---------:|--------------------:|
|            2.6767 |         1 |      157 |              2.5083 |
|            2.5718 |         2 |      314 |              2.449  |
|            2.5362 |         3 |      471 |              2.4451 |
...


### Top 2: `ab40cd3c4e_table1.csv`

|    Training Loss  |    Epoch  |    Step  |    Validation Loss  |
|------------------:|----------:|---------:|--------------------:|
|            2.6767 |         1 |      157 |              2.5083 |
|            2.5718 |         2 |      314 |              2.449  |
|            2.5362 |         3 |      471 |              2.4451 |
...


### Top 3: `3e9ad2e441_table1.csv`

|    Training Loss  |    Epoch  |    Step  |    Validation Loss  |
|------------------:|----------:|---------:|--------------------:|
|            2.6767 |         1 |      157 |              2.5083 |
|            2.5718 |         2 |      314 |              2.449  |
|            2.5362 |         3 |      471 |              2.4451 |
...

**ModelÂ â†’Â Titles**
- **RiKrim/distilbert-base-uncased-finetuned-imdb**:
    - Raw Titles: []
    - Valid Titles: []
- **baobao88/distilbert-base-uncased-finetuned-imdb**:
    - Raw Titles: []
    - Valid Titles: []
- **spyrok/distilbert-base-uncased-finetuned-imdb**:
    - Raw Titles: []
    - Valid Titles: []


### Top 4: `93220dec2c_table1.csv`

|    Training Loss  |    Epoch  |    Step  |    Validation Loss  |
|------------------:|----------:|---------:|--------------------:|
|            2.7028 |         1 |      157 |              2.4868 |
|            2.5735 |         2 |      314 |              2.4259 |
|            2.5327 |         3 |      471 |              2.4502 |
...

**ModelÂ â†’Â Titles**
- **Dylettante/distilbert-base-uncased-finetuned-imdb**:
    - Raw Titles: []
    - Valid Titles: []


### Top 5: `a68f746a30_table1.csv`

|    Training Loss  |    Epoch  |    Step  |    Validation Loss  |
|------------------:|----------:|---------:|--------------------:|
|            2.6864 |         1 |      157 |              2.5154 |
|            2.5723 |         2 |      314 |              2.5113 |
|            2.5318 |         3 |      471 |              2.4726 |
...

**ModelÂ â†’Â Titles**
- **san94/distilbert-base-uncased-finetuned-imdb**:
    - Raw Titles: []
    - Valid Titles: []


### Top 6: `54bfe02740_table1.csv`

|    Training Loss  |    Epoch  |    Step  |    Validation Loss  |
|------------------:|----------:|---------:|--------------------:|
|            2.6898 |         1 |      157 |              2.5423 |
|            2.5746 |         2 |      314 |              2.4453 |
|            2.5548 |         3 |      471 |              2.4528 |
...

**ModelÂ â†’Â Titles**
- **moonzi/distilbert-base-uncased-finetuned-imdb**:
    - Raw Titles: []
    - Valid Titles: []


### Top 7: `2c98f5c500_table1.csv`

|    Training Loss  |    Epoch  |    Step  |    Validation Loss  |
|------------------:|----------:|---------:|--------------------:|
|            2.6832 |         1 |      157 |              2.5232 |
|            2.5638 |         2 |      314 |              2.4494 |
|            2.5311 |         3 |      471 |              2.4769 |
...

**ModelÂ â†’Â Titles**
- **Gg1313/distilbert-base-uncased-finetuned_imdb**:
    - Raw Titles: []
    - Valid Titles: []



---

# Query Table: `995e0e2a9f_table1.csv`

## Query Table Content

|  Training Loss    |    Epoch  |    Step  |    Validation Loss  |
|:------------------|----------:|---------:|--------------------:|
| No log            |         1 |      180 |              1.7745 |
| No log            |         2 |      360 |              1.8828 |
| 1.0639            |         3 |      540 |              1.9312 |
| 1.0639            |         4 |      720 |              2.1928 |
| 1.0639            |         5 |      900 |              2.298  |
...

**Query Table Model â†’ Titles**
- **princetyagi/gelectra-base-germanquad-finetuned-squad**:
    - Raw Titles: []
    - Valid Titles: []

## Retrieved Tables

### Top 1: `53f68eeb49_table1.csv`

|  Training Loss    |    Epoch  |    Step  |    Validation Loss  |
|:------------------|----------:|---------:|--------------------:|
| No log            |         1 |      180 |              1.994  |
| No log            |         2 |      360 |              1.7339 |
| 2.5168            |         3 |      540 |              1.83   |
| 2.5168            |         4 |      720 |              1.9861 |
| 2.5168            |         5 |      900 |              2.1922 |
...

**ModelÂ â†’Â Titles**
- **princetyagi/bert-base-german-cased-finetuned-squad**:
    - Raw Titles: []
    - Valid Titles: []


### Top 2: `90bd508463_table1.csv`

|  Training Loss    |    Epoch  |    Step  |    Validation Loss  |
|:------------------|----------:|---------:|--------------------:|
| No log            |         1 |      180 |              2.7806 |
| No log            |         2 |      360 |              2.5746 |
| 2.7322            |         3 |      540 |              2.4898 |
| 2.7322            |         4 |      720 |              1.6754 |
| 2.7322            |         5 |      900 |              1.6187 |
...

**ModelÂ â†’Â Titles**
- **princetyagi/roberta-base-wechsel-german-finetuned-germanquad**:
    - Raw Titles: []
    - Valid Titles: []


### Top 3: `2821cc2fb3_table1.csv`

|    Training Loss  |    Epoch  |    Step  |    Validation Loss  |
|------------------:|----------:|---------:|--------------------:|
|            0.8725 |         1 |      180 |              0.673  |
|            0.6668 |         2 |      360 |              0.6203 |
|            0.6078 |         3 |      540 |              0.5739 |
|            0.5656 |         4 |      720 |              0.5537 |
|            0.5385 |         5 |      900 |              0.5483 |
...

**ModelÂ â†’Â Titles**
- **matr1xx/scibert_scivocab_uncased-finetuned-mol-mlm-0.3**:
    - Raw Titles: []
    - Valid Titles: []


### Top 4: `7a8b95dcd4_table1.csv`

|  Training Loss    |    Epoch  |    Step  |    Validation Loss  |
|:------------------|----------:|---------:|--------------------:|
| No log            |         1 |      208 |              2.2506 |
| No log            |         2 |      416 |              2.3121 |
| 1.909             |         3 |      624 |              2.8845 |
| 1.909             |         4 |      832 |              3.5883 |
| 0.5506            |         5 |     1040 |              4.0809 |
...

**ModelÂ â†’Â Titles**
- **intanm/fewshot-qa-004-20230614-001**:
    - Raw Titles: []
    - Valid Titles: []


### Top 5: `9efd812919_table1.csv`

|  Training Loss    |    Epoch  |    Step  |    Validation Loss  |
|:------------------|----------:|---------:|--------------------:|
| No log            |         1 |      200 |              2.2379 |
| No log            |         2 |      400 |              2.314  |
| 1.8489            |         3 |      600 |              3.0345 |
| 1.8489            |         4 |      800 |              3.5503 |
| 0.5002            |         5 |     1000 |              3.9071 |
...

**ModelÂ â†’Â Titles**
- **intanm/xlmrlarge-squad2-webis**:
    - Raw Titles: []
    - Valid Titles: []


### Top 6: `9d310edf39_table1.csv`

|  Training Loss    |    Epoch  |    Step  |    Validation Loss  |
|:------------------|----------:|---------:|--------------------:|
| No log            |         1 |      234 |              0.2011 |
| No log            |         2 |      468 |              0.2151 |
| 0.246             |         3 |      702 |              0.1992 |
| 0.246             |         4 |      936 |              0.1964 |
| 0.0694            |         5 |     1170 |              0.1924 |
...

**ModelÂ â†’Â Titles**
- **SOUMYADEEPSAR/mbert_CoLI_dravidian_kannada**:
    - Raw Titles: []
    - Valid Titles: []


### Top 7: `58e182cef0_table1.csv`

|  Training Loss    |    Epoch  |    Step  |    Validation Loss  |    Accuracy  |
|:------------------|----------:|---------:|--------------------:|-------------:|
| No log            |         1 |       40 |              1.9756 |       0.2313 |
| No log            |         2 |       80 |              1.6788 |       0.3937 |
| No log            |         3 |      120 |              1.5219 |       0.5375 |
| No log            |         4 |      160 |              1.4542 |       0.45   |
| No log            |         5 |      200 |              1.3923 |       0.5    |
...

**ModelÂ â†’Â Titles**
- **hmrizal/emotion_classification**:
    - Raw Titles: []
    - Valid Titles: []


### Top 8: `fba09f9510_table1.csv`

|  Training Loss    |    Epoch  |    Step  |    Validation Loss  |
|:------------------|----------:|---------:|--------------------:|
| No log            |         1 |       65 |              3.4665 |
| No log            |         2 |      130 |              2.8392 |
| No log            |         3 |      195 |              2.4838 |
| No log            |         4 |      260 |              2.3667 |
| No log            |         5 |      325 |              2.3424 |
...

**ModelÂ â†’Â Titles**
- **likhith231/distilbert-base-uncased-finetuned-squad**:
    - Raw Titles: []
    - Valid Titles: []


### Top 9: `f1d575ef90_table1.csv`

|    Training Loss  |    Epoch  |    Step  |    Validation Loss  |    Accuracy  |
|------------------:|----------:|---------:|--------------------:|-------------:|
|            1.9224 |         1 |      113 |              1.8645 |         0.55 |
|            1.1747 |         2 |      226 |              1.2232 |         0.66 |
|            1.0823 |         3 |      339 |              1.0418 |         0.69 |
|            0.6272 |         4 |      452 |              0.7845 |         0.75 |
|            0.5903 |         5 |      565 |              0.6946 |         0.78 |
...

**ModelÂ â†’Â Titles**
- **ruhullah1/distilhubert-finetuned-gtzan**:
    - Raw Titles: []
    - Valid Titles: []



---
